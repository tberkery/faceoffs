{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Tad/Documents/faceoffs/data_imputed_with_event_zone_2016_to_2018.csv')\n",
    "print(\"data read\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca fitting\n",
      "[[-2.77912132e+02 -5.55401373e+02  1.35365684e+02 ... -1.37973712e+01\n",
      "   9.26414737e+00  7.08829204e+00]\n",
      " [-2.77912132e+02 -5.55401373e+02  1.35365684e+02 ... -1.37973712e+01\n",
      "   9.26414737e+00  7.08829204e+00]\n",
      " [ 2.47725657e+03 -1.58784321e+03 -2.81096680e+01 ... -9.44780177e+00\n",
      "   8.83351844e+00 -2.75307563e+00]\n",
      " ...\n",
      " [-3.82489735e+02 -6.57139235e+02  1.69555141e+02 ... -8.01341966e+00\n",
      "   5.17362390e+00  3.52108828e+01]\n",
      " [ 2.07224344e+03 -1.84284682e+03 -9.73140726e+01 ... -3.28501777e+01\n",
      "   3.05928707e+01  1.89974541e+01]\n",
      " [-4.66836903e+02 -1.34533008e+02 -6.23398819e+02 ...  1.29321558e+00\n",
      "  -2.25531648e+01  1.38363171e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Principal Component Analysis\n",
    "data_all = data.dropna()\n",
    "#data_all = data_all[data_all['event_zone'] == 'Off']\n",
    "data = data_all.select_dtypes(['number'])\n",
    "x = data.loc[:, data.columns != 'faceoff_losing_team_xG_since_faceoff']\n",
    "x = x.loc[:, x.columns != 'faceoff_winning_team_xG_since_faceoff']\n",
    "x = x.loc[:, x.columns != 'event_zone'] # We don't want event_zone in the principal components\n",
    "y = data['faceoff_winning_team_xG_since_faceoff']\n",
    "pca = PCA(n_components = 100)\n",
    "print(\"pca fitting\")\n",
    "principal_components = pca.fit_transform(x)\n",
    "print(principal_components)\n",
    "principal_components_df = pd.DataFrame(principal_components)\n",
    "principal_components_df.to_csv(\"principal_components_newest.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed train-test split\n"
     ]
    }
   ],
   "source": [
    "# Prep Train and Test Data\n",
    "objectives = data['faceoff_winning_team_xG_since_faceoff']\n",
    "principal_components_df['faceoff_winning_team_xG_since_faceoff'] = objectives\n",
    "data_no_na = principal_components_df.dropna() # FLAG\n",
    "X = data_no_na.loc[:, data_no_na.columns != 'faceoff_losing_team_xG_since_faceoff']\n",
    "X = X.loc[:, X.columns != 'faceoff_winning_team_xG_since_faceoff']\n",
    "X = OneHotEncoder(categories = 'auto').fit_transform(X)\n",
    "y = data_no_na['faceoff_winning_team_xG_since_faceoff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(\"completed train-test split\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-08 01:41:54.676341\n"
     ]
    }
   ],
   "source": [
    "# Build initial, untuned random forest model\n",
    "print(datetime.now())\n",
    "# rf_initial = RandomForestRegressor().fit(x_train, y_train)\n",
    "# print(\"completed RandomForestRegressor initial fitting\")\n",
    "# prediction_initial = rf_initial.predict(x_test)\n",
    "# mse_initial = mean_squared_error(y_test, prediction_initial)\n",
    "# rmse_initial = mse_initial ** .5\n",
    "# print(mse_initial)\n",
    "# print(rmse_initial)\n",
    "# print(datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-08 01:42:02.166391\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x17ed5614610 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\Users\\Tad\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial Big Picture Tuning using RandomizedSearchCV\n",
    "print(datetime.now())\n",
    "\n",
    "# random_grid = { # FLAG\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [10, 25, 50, 100, 500, 1000],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "#     'min_samples_leaf': [5, 10],\n",
    "#     'min_samples_split': [5, 10, 25, 50],\n",
    "#     'n_estimators': [100, 250, 500, 1000],\n",
    "# }\n",
    "random_grid = { # FLAG\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 25, 50, 100, 500, 1000],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_leaf': [5, 10, 25, 50],\n",
    "    'min_samples_split': [5, 10, 25, 50, 100],\n",
    "    'n_estimators': [100, 200, 400, 600, 800, 1000, 2000, 5000],\n",
    "}\n",
    "\n",
    "# SOLELY FOR TESTING WHETHER CODE COMPILES (FLAG)\n",
    "# random_grid = {\n",
    "#     'bootstrap': [True],\n",
    "#     'max_depth': [5],\n",
    "#     'max_features': ['auto'],\n",
    "#     'min_samples_leaf': [2],\n",
    "#     'min_samples_split': [2],\n",
    "#     'n_estimators': [15],\n",
    "# }\n",
    "\n",
    "rf_tuning = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf_tuning, param_distributions = random_grid, n_iter = 10, cv = 3, verbose = 2, random_state = 42, n_jobs = -1) # FLAG (n_iter)\n",
    "rf_fit_output = rf_random.fit(x_train, y_train)\n",
    "print(\"writing joblib\")\n",
    "dump(rf_fit_output, 'rf_randomized_search_cv_fit_off_win.joblib') #FLAG... change suffix\n",
    "print(datetime.now())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def evaluate(model, test_features, test_labels):\n",
    "#     predictions = model.predict(test_features)\n",
    "#     errors = abs(predictions - test_labels)\n",
    "#     mape = 100 * np.mean(errors / test_labels)\n",
    "#     accuracy = 100 - mape\n",
    "#     print('Model Performance')\n",
    "#     print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "#     print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "#\n",
    "#     return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "# random_accuracy = evaluate(best_random, x_test, y_test)\n",
    "\n",
    "predictions = rf_fit_output.predict(x_test)\n",
    "errors = abs(predictions - y_test)\n",
    "# from sklearn.metrics import r2_score\n",
    "# r_sq = r2_score(y_test, predictions)\n",
    "# mse_grid = mean_squared_error(y_test, predictions)\n",
    "# print(mse_grid)\n",
    "# rmse_grid = mse_grid ** .5\n",
    "# print(rmse_grid)\n",
    "#\n",
    "# # Display the performance metrics\n",
    "# print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "# mape = np.mean(100 * (errors / y_test))\n",
    "# accuracy = 100 - np.mean(mape[np.isfinite(mape)])\n",
    "# print('Accuracy:', round(accuracy, 2), '%.')\n",
    "# See https://stackoverflow.com/questions/58067438/mape-mean-absolute-percentage-error-measurement-in-python-result-in-error#:~:text=mape%20%3D%20100%20*%20(errors%20%2F,')\n",
    "\n",
    "best_bootstrap = best_random.bootstrap\n",
    "best_max_depth = best_random.max_depth\n",
    "best_max_features = best_random.max_features\n",
    "best_min_samples_leaf = best_random.min_samples_leaf\n",
    "best_min_samples_split = best_random.min_samples_split\n",
    "best_n_estimators = best_random.n_estimators\n",
    "\n",
    "best_parameters = rf_fit_output.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_best_param = RandomForestRegressor(bootstrap = best_bootstrap,\n",
    "                                      max_depth = best_max_depth,\n",
    "                                      max_features = best_max_features,\n",
    "                                      min_samples_leaf = best_min_samples_leaf,\n",
    "                                      min_samples_split = best_min_samples_split,\n",
    "                                      n_estimators = best_n_estimators)\n",
    "rf_best_param_fit = rf_best_param.fit(x_train, y_train)\n",
    "\n",
    "dump(rf_best_param_fit, 'rf_best_parameters_fit_off_win.joblib') # FLAG... change suffix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# var_imps = rf_best_param_fit.feature_importances_\n",
    "#\n",
    "# def plot_feature_importance(importance,names,model_type):\n",
    "#     #Create arrays from feature importance and feature names\n",
    "#     feature_importance = np.array(importance)\n",
    "#     feature_names = np.array(names)\n",
    "#\n",
    "#     #Create a DataFrame using a Dictionary\n",
    "#     df ={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "#     fi_df = pd.DataFrame(df)\n",
    "#\n",
    "#     #Sort the DataFrame in order decreasing feature importance\n",
    "#     fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "#\n",
    "#     #Define size of bar plot\n",
    "#     plt.figure(figsize=(10,8))\n",
    "#     #Plot Searborn bar chart\n",
    "#     sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "#     #Add chart labels\n",
    "#     plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "#     plt.xlabel('FEATURE IMPORTANCE')\n",
    "#     plt.ylabel('FEATURE NAMES')\n",
    "# plot_feature_importance(rf_best_param_fit.feature_importances_,x_train.columns,'RANDOM FOREST')\n",
    "#\n",
    "# feat_importances_series = pd.Series(var_imps, index=x_train.columns)\n",
    "# feat_importances_series.nlargest(20).plot(kind='barh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}