{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceoffsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data = self.data.iloc[idx, 1:]\n",
    "        data = np.array([data])\n",
    "        data = data.reshape(-1, 2)\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Data Directory ##TODO: Please fill in the appropriate directory\n",
    "# Uncomment appropriate directory based on whether using local laptop, Google Colab, or AWS EC2 Instance.\n",
    "#data_dir = \"/content/gdrive/MyDrive/HW6_data (1)/HW6_data\"\n",
    "#data_dir = \"/home/ubuntu/unsupervised-and-transfer-learning/hw6_data_copy/HW6_data\"\n",
    "#data_dir = \"C:/Users/Tad/Documents/unsupervised-and-transfer-learning/hw6_data_copy/HW6_data\"\n",
    "#data_dir = \"C:/Users/Tad/Documents/unsupervised-and-transfer-learning/HW6_data\"\n",
    "data_dir = \"/Users/Tad/Documents/faceoffs\"\n",
    "segmentation_data_dir = f\"{data_dir}/segmentation/\"\n",
    "colorization_data_dir = f\"{data_dir}/colorization/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial = pd.read_csv(\"training_data_all_offensive_offensive.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    game_id_x  season_x  game_seconds  event_index  game_period  coords_x  \\\n",
      "0   -1.798257 -1.797913     -0.715929    -0.712210    -0.606279 -0.531820   \n",
      "1   -1.798257 -1.797913     -0.697547    -0.677103    -0.606279 -0.531820   \n",
      "2   -1.798257 -1.797913      0.039564     0.060154    -0.606279 -0.531820   \n",
      "3   -1.798257 -1.797913      0.210515     0.255753    -0.606279  1.880391   \n",
      "4   -1.798257 -1.797913      0.445803     0.471414     0.764344 -0.531820   \n",
      "..        ...       ...           ...          ...          ...       ...   \n",
      "95  -1.798252 -1.797913     -0.357483    -0.326028    -0.606279  1.880391   \n",
      "96  -1.798252 -1.797913      0.458670     0.476429     0.764344  1.880391   \n",
      "97  -1.798252 -1.797913      0.554256     0.556675     0.764344  1.880391   \n",
      "98  -1.798252 -1.797913      0.604806     0.596797     0.764344 -0.531820   \n",
      "99  -1.798252 -1.797913      0.816197     0.772335     0.764344  1.880391   \n",
      "\n",
      "    coords_y  home_score  away_score  event_distance  ...  OL_team_Lose_D2  \\\n",
      "0  -0.532003   -0.525466   -0.518676        -0.00558  ...         0.183869   \n",
      "1   1.879738   -0.525466   -0.518676        -0.00558  ...         0.183869   \n",
      "2   1.879738   -0.525466   -0.518676        -0.00558  ...         0.183869   \n",
      "3   1.879738   -0.525466    0.371798        -0.00558  ...         1.223635   \n",
      "4  -0.532003   -0.525466    2.152746        -0.00558  ...         1.223635   \n",
      "..       ...         ...         ...             ...  ...              ...   \n",
      "95 -0.532003    0.294989   -0.518676        -0.00558  ...         0.183869   \n",
      "96 -0.532003    0.294989    0.371798        -0.00558  ...         1.570223   \n",
      "97  1.879738    0.294989    0.371798        -0.00558  ...         0.530458   \n",
      "98 -0.532003    0.294989    0.371798        -0.00558  ...         0.183869   \n",
      "99  1.879738    1.115444    0.371798        -0.00558  ...         1.570223   \n",
      "\n",
      "    Points_team_Lose_D2  Points_Percent_team_Lose_D2  GF_team_Lose_D2  \\\n",
      "0              0.142426                     0.136907         0.243305   \n",
      "1              0.142426                     0.136907         0.243305   \n",
      "2              0.142426                     0.136907         0.243305   \n",
      "3              0.682674                     0.677577         0.243305   \n",
      "4              0.682674                     0.677577         0.243305   \n",
      "..                  ...                          ...              ...   \n",
      "95             0.142426                     0.136907        -0.399900   \n",
      "96            -2.138621                    -2.133906        -1.757778   \n",
      "97            -0.397822                    -0.403763        -0.757236   \n",
      "98             0.142426                     0.136907        -0.399900   \n",
      "99            -2.138621                    -2.133906        -1.757778   \n",
      "\n",
      "    GA_team_Lose_D2  G_Plus_Minus_team_Lose_D2  Sh_Percent_team_Lose_D2  \\\n",
      "0         -0.289002                   0.303134                -0.331166   \n",
      "1         -0.289002                   0.303134                -0.331166   \n",
      "2         -0.289002                   0.303134                -0.331166   \n",
      "3         -0.916996                   0.606845                -0.248876   \n",
      "4         -0.916996                   0.606845                -0.248876   \n",
      "..              ...                        ...                      ...   \n",
      "95         0.024995                  -0.239207                 0.162571   \n",
      "96         2.357544                  -2.191634                -1.565506   \n",
      "97        -0.109575                  -0.391062                -1.071770   \n",
      "98         0.024995                  -0.239207                 0.162571   \n",
      "99         2.357544                  -2.191634                -1.565506   \n",
      "\n",
      "    Sv_Percent_team_Lose_D2  Lose_D2_Perc    net_xg  \n",
      "0                  1.663204      0.607807  0.089291  \n",
      "1                  1.663204      0.711853  0.073043  \n",
      "2                  1.663204      0.791419  0.112887  \n",
      "3                  1.663204      1.177871  0.051333  \n",
      "4                  1.663204     -1.649393  0.073019  \n",
      "..                      ...           ...       ...  \n",
      "95                 0.396731     -2.288974  0.015949  \n",
      "96                -1.819598      0.565055  0.020040  \n",
      "97                 0.080112     -0.397050  0.022755  \n",
      "98                 0.396731      0.966863  0.024117  \n",
      "99                -1.819598      0.744529  0.082255  \n",
      "\n",
      "[100 rows x 1503 columns]\n",
      "torch.Size([60387, 1502])\n"
     ]
    }
   ],
   "source": [
    "data_no_na = data_initial.dropna() # data should already have no NAs due to numerical imputation\n",
    "data = data_no_na.select_dtypes(['number'])\n",
    "print(data.head(100))\n",
    "x = data.loc[:, data.columns != 'net_xg']\n",
    "x = x.loc[:, x.columns != 'net_xg']\n",
    "y = data['net_xg']\n",
    "\n",
    "X_train, X_intermediate, y_train, y_intermediate = train_test_split(x, y, train_size = 0.65, test_size=0.35, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_intermediate, y_intermediate, test_size=0.571, random_state=42)\n",
    "# Above two lines in unison accomplish a 65-15-20 split for train-test-validation\n",
    "\n",
    "X_train = torch.from_numpy(X_train.to_numpy())\n",
    "X_val = torch.from_numpy(X_val.to_numpy())\n",
    "X_test = torch.from_numpy(X_test.to_numpy())\n",
    "\n",
    "y_train = torch.from_numpy(y_train.to_numpy())\n",
    "y_val = torch.from_numpy(y_val.to_numpy())\n",
    "y_test = torch.from_numpy(y_test.to_numpy())\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60387, 30])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaNeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(VanillaNeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1500, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 750)\n",
    "        self.fc3 = nn.Linear(750, 500)\n",
    "        self.fc4 = nn.Linear(500, 500)\n",
    "        self.fc5 = nn.Linear(500, 500)\n",
    "        self.fc6 = nn.Linear(500, 500)\n",
    "        self.fc7 = nn.Linear(500, 250)\n",
    "        self.fc8 = nn.Linear(250, 100)\n",
    "        self.fc9 = nn.Linear(100, 50)\n",
    "        self.fc10 = nn.Linear(50, 1) # output singular prediction\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1 = self.fc1(torch.nn.functional.relu(x))\n",
    "        x_2 = self.fc2(torch.nn.functional.relu(x_1))\n",
    "        x_3 = self.fc3(torch.nn.functional.relu(x_2))\n",
    "        x_4 = self.fc4(torch.nn.functional.relu(x_3))\n",
    "        x_5 = self.fc5(torch.nn.functional.relu(x_4))\n",
    "        x_6 = self.fc6(torch.nn.functional.relu(x_5))\n",
    "        x_7 = self.fc7(torch.nn.functional.relu(x_6))\n",
    "        x_8 = self.fc8(torch.nn.functional.relu(x_7))\n",
    "        x_9 = self.fc9(torch.nn.functional.relu(x_8))\n",
    "        x_10 = self.fc10(torch.nn.functional.relu(x_9))\n",
    "        return x_10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
